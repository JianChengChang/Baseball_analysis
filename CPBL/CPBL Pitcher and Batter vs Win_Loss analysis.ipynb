{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "demanding-dutch",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honey-suffering",
   "metadata": {},
   "source": [
    "### Read Data\n",
    "\n",
    "Read data which was parsed from CPBL and CPBLSTAT  \n",
    "CPBL Data: 2021 all game's Win/Loss, Home/Away, Batting Order and the Player's Name with PAs and SP/RP's Name with PAs  \n",
    "CPBLSTAT: 2021 all player's advance baseball index before 8/11, include batting: 'BABIP','wOBA','wRC+'  Pitching: 'FIP','WAR'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "stuffed-possession",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set os\n",
    "os.chdir(r'D:\\100. Issue\\24. CPBL')\n",
    "\n",
    "#read data\n",
    "Score_board = pd.read_csv('board.csv')\n",
    "Score_board['Win'] = Score_board['Win'].astype(str)\n",
    "Score_board['Home'] = Score_board['Home'].astype(str)\n",
    "\n",
    "Batter_list = pd.read_csv('batter_list.csv')\n",
    "Pitcher_list = pd.read_csv('pitcher_list.csv')\n",
    "Batting_stat = pd.read_csv('batting_stat.csv')\n",
    "Pitching_stat = pd.read_csv('pitching_stat.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paperback-madonna",
   "metadata": {},
   "source": [
    "### Create function for the weighted average of advance baseball index for all batting order and SP/RP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "white-victorian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weighted average\n",
    "def weighted_average(df,col, weight_col):\n",
    "    return np.average(df[col], weights = df[weight_col])\n",
    "\n",
    "def groupby_cal(df,col):\n",
    "    return df.groupby(['Win','Date','No','Team','Home','Order'],as_index=False).apply(lambda x:weighted_average(x,col,'BA'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranking-husband",
   "metadata": {},
   "source": [
    "### Data cleaning\n",
    "\n",
    "Merge the Score_board, Batter_List, Batting_stat   \n",
    "and leave 'Win','Date','No','Team','Home','Order','BA','OPS+','BB/K','BABIP','wOBA','wRC+'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "addressed-dating",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Batting\n",
    "# Merge data\n",
    "Batting_board = Score_board.merge(Batter_list,on=['Date','No','Team'])\n",
    "Batting_board = Batting_board.merge(Batting_stat, left_on = 'Name', right_on='NAME', how = 'left')\n",
    "Batting_board = Batting_board[['Win','Date','No','Team','Home','Order','BA','OPS+','BB/K','BABIP','wOBA','wRC+']]\n",
    "Batting_board.fillna(0, inplace=True)\n",
    "Batting_board['BB/K'] = Batting_board['BB/K'].replace('-','0')\n",
    "Batting_board.iloc[:,7:] = Batting_board.iloc[:,7:].apply(lambda x: x.astype(float))\n",
    "Batting_board = Batting_board[Batting_board.Win != '0.5']\n",
    "Batting_board = Batting_board[Batting_board.BA != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textile-calvin",
   "metadata": {},
   "source": [
    "Calculate the weighted average for the advance batting index by PAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "under-links",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for i in ['OPS+','BB/K','BABIP','wOBA','wRC+']:\n",
    "    df = groupby_cal(Batting_board,i)\n",
    "    df.columns = ['Win', 'Date', 'No', 'Team', 'Home', 'Order', i]\n",
    "    df_list.append(df)\n",
    "\n",
    "for i in range(0,len(df_list)):\n",
    "    if i == 0:\n",
    "        df = df_list[0]\n",
    "    else:\n",
    "        df = df.merge(df_list[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uniform-lobby",
   "metadata": {},
   "source": [
    "DataFrame reshape  \n",
    "Long data transfer to wide data by batting order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "subtle-asbestos",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data reshape\n",
    "df = df.sort_values(by=['Date','No','Team','Order'])\n",
    "df.reset_index(drop=True, inplace = True)\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for item in ['OPS+','BB/K','BABIP','wOBA','wRC+']:\n",
    "    ls_all = []\n",
    "    ls = []\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        if df.Order[i] == 1:\n",
    "            ls_all.append(ls)\n",
    "            ls = []\n",
    "            ls.extend(df.iloc[i,0:5].tolist())\n",
    "            ls.append(df[item][i])\n",
    "        else:\n",
    "            ls.append(df[item][i])\n",
    "\n",
    "    df_list.append(ls_all[1:])\n",
    "\n",
    "items = ['OPS+','BB/K','BABIP','wOBA','wRC+']\n",
    "for i in range(len(df_list)):\n",
    "    col = [items[i] + '_' + str(j) for j in range(1,10)]\n",
    "    column_name = ['Win','Date','No','Team','Home']\n",
    "    column_name.extend(col)\n",
    "    if i == 0:\n",
    "        df_batting = pd.DataFrame(df_list[i], columns= column_name)\n",
    "    else:\n",
    "        df_batting = df_batting.merge(pd.DataFrame(df_list[i], columns= column_name))   \n",
    "\n",
    "del Batting_board, col, column_name, df, df_list, i, item, items, ls, ls_all\n",
    "df_batting.dropna(inplace=True)\n",
    "df_batting.to_csv('df_batting',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nutritional-calibration",
   "metadata": {},
   "source": [
    "Do the same action with Pitcher data  \n",
    "Data cleaning  \n",
    "Calculate the advance pitching index  \n",
    "then do the data reshape by pitcher position  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "virgin-pencil",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pitcher\n",
    "# Merge data\n",
    "Pitching_board = Score_board.merge(Pitcher_list,on=['Date','No','Team'])\n",
    "Pitching_board = Pitching_board.merge(Pitching_stat, left_on = 'Name', right_on='NAME', how = 'left')\n",
    "Pitching_board = Pitching_board[['Win','Date','No','Team','Home','Order','INN','BA','FIP','WAR']]\n",
    "Pitching_board.Order[Pitching_board.Order != 1] = 'RP'\n",
    "Pitching_board.Order[Pitching_board.Order == 1] = 'SP'\n",
    "Pitching_board.iloc[:,6:] = Pitching_board.iloc[:,6:].apply(lambda x: x.astype(float))\n",
    "Pitching_board = Pitching_board[Pitching_board.Win != '0.5']\n",
    "\n",
    "# weighted average\n",
    "df_list = []\n",
    "for i in ['FIP','WAR']:\n",
    "    df = groupby_cal(Pitching_board,i)\n",
    "    df.columns = ['Win', 'Date', 'No', 'Team', 'Home', 'Order', i]\n",
    "    df_list.append(df)\n",
    "\n",
    "for i in range(0,len(df_list)):\n",
    "    if i == 0:\n",
    "        df = df_list[0]\n",
    "    else:\n",
    "        df = df.merge(df_list[i])\n",
    "\n",
    "# Data reshape\n",
    "df = df.sort_values(by=['Date','No','Team','Order'], ascending=[True, True, True,False])\n",
    "df.reset_index(drop=True, inplace = True)\n",
    "\n",
    "df_list = []\n",
    "for item in ['FIP','WAR']:\n",
    "    ls_all = []\n",
    "    ls = []\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        if df.Order[i] == 'SP':\n",
    "            ls_all.append(ls)\n",
    "            ls = []\n",
    "            ls.extend(df.iloc[i,0:5].tolist())\n",
    "            ls.append(df[item][i])\n",
    "        else:\n",
    "            ls.append(df[item][i])\n",
    "\n",
    "    df_list.append(ls_all[1:])\n",
    "\n",
    "items = ['FIP','WAR']\n",
    "for i in range(len(df_list)):\n",
    "    col = [items[i] + '_' + j for j in ['SP','RP']]\n",
    "    column_name = ['Win','Date','No','Team','Home']\n",
    "    column_name.extend(col)\n",
    "    if i == 0:\n",
    "        df_pitching = pd.DataFrame(df_list[i], columns= column_name)\n",
    "    else:\n",
    "        df_pitching = df_pitching.merge(pd.DataFrame(df_list[i], columns= column_name))   \n",
    "\n",
    "del Pitching_board, col, column_name, df, df_list, i, item, items, ls, ls_all\n",
    "df_pitching.fillna(0, inplace=True)\n",
    "df_pitching.to_csv('df_pitching',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surrounded-shaft",
   "metadata": {},
   "source": [
    "### Prepare to fit a model for Win/Loss prediction\n",
    "\n",
    "Merge the batting data and pitching data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "referenced-input",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge pitching and batting\n",
    "df_comp = df_pitching.merge(df_batting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limited-woman",
   "metadata": {},
   "source": [
    "Split data into X train, X test by date 2021/08/11  \n",
    "then split data into X and y  \n",
    "y is our target, and it is 'Win'  \n",
    "X is independent variable, exclude 'Date','No','Team','Win'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "centered-plasma",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data to X and y\n",
    "\n",
    "X_train = df_comp.iloc[:274,:]\n",
    "X_test = df_comp.iloc[274:,:]\n",
    "\n",
    "target = 'Win'\n",
    "feature = [col for col in df_comp.columns if col not in ['Date','No','Team','Win']]\n",
    "\n",
    "y_train = X_train[target]\n",
    "X_train = X_train[feature]\n",
    "y_test = X_test[target]\n",
    "X_test = X_test[feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authentic-injection",
   "metadata": {},
   "source": [
    "Execute the standardscaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "unauthorized-convention",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaler\n",
    "scaler = StandardScaler()\n",
    "X_train.iloc[:,1:] = scaler.fit_transform(X_train.iloc[:,1:])\n",
    "X_test.iloc[:,1:] = scaler.transform(X_test.iloc[:,1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comic-chamber",
   "metadata": {},
   "source": [
    "### Fit model: Logistic Regression\n",
    "  \n",
    "Use package statsmodel to fit the Logistic Regression  \n",
    "Why don't use sklearn  \n",
    "Because statsmodel has summary function  \n",
    "This function can help us to find which variable is significantly influences the target  \n",
    "And check the model's R square score   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "grateful-armstrong",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.568059\n",
      "         Iterations 7\n"
     ]
    }
   ],
   "source": [
    "log_reg = sm.Logit(y_train.astype(float), X_train.astype(float)).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "accessible-version",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>Win</td>       <th>  No. Observations:  </th>  <td>   274</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   224</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>    49</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Fri, 20 Aug 2021</td> <th>  Pseudo R-squ.:     </th>  <td>0.1805</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>10:06:06</td>     <th>  Log-Likelihood:    </th> <td> -155.65</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -189.92</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>  <td>0.03396</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>        <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Home</th>    <td>   -0.1375</td> <td>    0.207</td> <td>   -0.663</td> <td> 0.507</td> <td>   -0.544</td> <td>    0.269</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FIP_SP</th>  <td>   -0.4355</td> <td>    0.298</td> <td>   -1.462</td> <td> 0.144</td> <td>   -1.019</td> <td>    0.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FIP_RP</th>  <td>   -0.6125</td> <td>    0.261</td> <td>   -2.345</td> <td> 0.019</td> <td>   -1.125</td> <td>   -0.101</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>WAR_SP</th>  <td>    0.1019</td> <td>    0.279</td> <td>    0.365</td> <td> 0.715</td> <td>   -0.446</td> <td>    0.650</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>WAR_RP</th>  <td>   -0.1953</td> <td>    0.209</td> <td>   -0.936</td> <td> 0.349</td> <td>   -0.604</td> <td>    0.213</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>OPS+_1</th>  <td>    0.2028</td> <td>    1.295</td> <td>    0.157</td> <td> 0.876</td> <td>   -2.334</td> <td>    2.740</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>OPS+_2</th>  <td>    1.1703</td> <td>    1.011</td> <td>    1.158</td> <td> 0.247</td> <td>   -0.811</td> <td>    3.151</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>OPS+_3</th>  <td>    3.3496</td> <td>    1.900</td> <td>    1.763</td> <td> 0.078</td> <td>   -0.374</td> <td>    7.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>OPS+_4</th>  <td>   -0.9504</td> <td>    1.381</td> <td>   -0.688</td> <td> 0.491</td> <td>   -3.657</td> <td>    1.756</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>OPS+_5</th>  <td>    0.2036</td> <td>    1.803</td> <td>    0.113</td> <td> 0.910</td> <td>   -3.330</td> <td>    3.737</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>OPS+_6</th>  <td>    0.9630</td> <td>    1.357</td> <td>    0.710</td> <td> 0.478</td> <td>   -1.696</td> <td>    3.622</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>OPS+_7</th>  <td>   -0.6260</td> <td>    0.748</td> <td>   -0.837</td> <td> 0.402</td> <td>   -2.091</td> <td>    0.839</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>OPS+_8</th>  <td>   -0.2688</td> <td>    0.664</td> <td>   -0.405</td> <td> 0.685</td> <td>   -1.569</td> <td>    1.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>OPS+_9</th>  <td>   -0.9037</td> <td>    0.888</td> <td>   -1.018</td> <td> 0.309</td> <td>   -2.644</td> <td>    0.836</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BB/K_1</th>  <td>   -0.1484</td> <td>    0.333</td> <td>   -0.445</td> <td> 0.656</td> <td>   -0.802</td> <td>    0.505</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BB/K_2</th>  <td>    0.2010</td> <td>    0.259</td> <td>    0.777</td> <td> 0.437</td> <td>   -0.306</td> <td>    0.708</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BB/K_3</th>  <td>   -0.0593</td> <td>    0.252</td> <td>   -0.235</td> <td> 0.814</td> <td>   -0.554</td> <td>    0.435</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BB/K_4</th>  <td>   -0.5134</td> <td>    0.284</td> <td>   -1.810</td> <td> 0.070</td> <td>   -1.069</td> <td>    0.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BB/K_5</th>  <td>    0.0484</td> <td>    0.229</td> <td>    0.211</td> <td> 0.833</td> <td>   -0.401</td> <td>    0.498</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BB/K_6</th>  <td>    0.0999</td> <td>    0.179</td> <td>    0.557</td> <td> 0.577</td> <td>   -0.251</td> <td>    0.451</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BB/K_7</th>  <td>   -0.0046</td> <td>    0.185</td> <td>   -0.025</td> <td> 0.980</td> <td>   -0.368</td> <td>    0.358</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BB/K_8</th>  <td>   -0.0558</td> <td>    0.253</td> <td>   -0.221</td> <td> 0.825</td> <td>   -0.552</td> <td>    0.440</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BB/K_9</th>  <td>    0.0833</td> <td>    0.221</td> <td>    0.377</td> <td> 0.706</td> <td>   -0.350</td> <td>    0.517</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BABIP_1</th> <td>   -0.0005</td> <td>    0.374</td> <td>   -0.001</td> <td> 0.999</td> <td>   -0.734</td> <td>    0.733</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BABIP_2</th> <td>    0.1457</td> <td>    0.261</td> <td>    0.558</td> <td> 0.577</td> <td>   -0.366</td> <td>    0.657</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BABIP_3</th> <td>   -0.4921</td> <td>    0.357</td> <td>   -1.380</td> <td> 0.167</td> <td>   -1.191</td> <td>    0.207</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BABIP_4</th> <td>   -0.1104</td> <td>    0.524</td> <td>   -0.211</td> <td> 0.833</td> <td>   -1.137</td> <td>    0.916</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BABIP_5</th> <td>   -0.3681</td> <td>    0.271</td> <td>   -1.360</td> <td> 0.174</td> <td>   -0.898</td> <td>    0.162</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BABIP_6</th> <td>    0.3748</td> <td>    0.344</td> <td>    1.090</td> <td> 0.276</td> <td>   -0.299</td> <td>    1.049</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BABIP_7</th> <td>    0.1804</td> <td>    0.287</td> <td>    0.629</td> <td> 0.529</td> <td>   -0.382</td> <td>    0.743</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BABIP_8</th> <td>    0.1978</td> <td>    0.333</td> <td>    0.593</td> <td> 0.553</td> <td>   -0.456</td> <td>    0.851</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BABIP_9</th> <td>    0.2449</td> <td>    0.324</td> <td>    0.756</td> <td> 0.449</td> <td>   -0.390</td> <td>    0.880</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wOBA_1</th>  <td>   28.5642</td> <td>   43.954</td> <td>    0.650</td> <td> 0.516</td> <td>  -57.584</td> <td>  114.712</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wOBA_2</th>  <td>  -24.3056</td> <td>   28.623</td> <td>   -0.849</td> <td> 0.396</td> <td>  -80.406</td> <td>   31.795</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wOBA_3</th>  <td>    8.5220</td> <td>   34.212</td> <td>    0.249</td> <td> 0.803</td> <td>  -58.532</td> <td>   75.576</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wOBA_4</th>  <td>  -46.2625</td> <td>   45.454</td> <td>   -1.018</td> <td> 0.309</td> <td> -135.352</td> <td>   42.827</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wOBA_5</th>  <td>   45.2661</td> <td>   31.977</td> <td>    1.416</td> <td> 0.157</td> <td>  -17.408</td> <td>  107.940</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wOBA_6</th>  <td>   -5.5840</td> <td>   39.549</td> <td>   -0.141</td> <td> 0.888</td> <td>  -83.099</td> <td>   71.931</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wOBA_7</th>  <td>   31.8981</td> <td>   32.745</td> <td>    0.974</td> <td> 0.330</td> <td>  -32.280</td> <td>   96.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wOBA_8</th>  <td>  -53.9648</td> <td>   45.479</td> <td>   -1.187</td> <td> 0.235</td> <td> -143.101</td> <td>   35.172</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wOBA_9</th>  <td>   22.1206</td> <td>   43.547</td> <td>    0.508</td> <td> 0.611</td> <td>  -63.229</td> <td>  107.471</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wRC+_1</th>  <td>  -28.3870</td> <td>   44.209</td> <td>   -0.642</td> <td> 0.521</td> <td> -115.035</td> <td>   58.261</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wRC+_2</th>  <td>   23.3727</td> <td>   28.436</td> <td>    0.822</td> <td> 0.411</td> <td>  -32.360</td> <td>   79.106</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wRC+_3</th>  <td>  -11.1826</td> <td>   33.702</td> <td>   -0.332</td> <td> 0.740</td> <td>  -77.236</td> <td>   54.871</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wRC+_4</th>  <td>   47.5405</td> <td>   45.667</td> <td>    1.041</td> <td> 0.298</td> <td>  -41.965</td> <td>  137.046</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wRC+_5</th>  <td>  -45.0429</td> <td>   31.816</td> <td>   -1.416</td> <td> 0.157</td> <td> -107.402</td> <td>   17.316</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wRC+_6</th>  <td>    4.1075</td> <td>   39.682</td> <td>    0.104</td> <td> 0.918</td> <td>  -73.668</td> <td>   81.883</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wRC+_7</th>  <td>  -31.2643</td> <td>   32.728</td> <td>   -0.955</td> <td> 0.339</td> <td>  -95.410</td> <td>   32.881</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wRC+_8</th>  <td>   53.9820</td> <td>   45.333</td> <td>    1.191</td> <td> 0.234</td> <td>  -34.870</td> <td>  142.834</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wRC+_9</th>  <td>  -21.3938</td> <td>   43.495</td> <td>   -0.492</td> <td> 0.623</td> <td> -106.642</td> <td>   63.854</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                    Win   No. Observations:                  274\n",
       "Model:                          Logit   Df Residuals:                      224\n",
       "Method:                           MLE   Df Model:                           49\n",
       "Date:                Fri, 20 Aug 2021   Pseudo R-squ.:                  0.1805\n",
       "Time:                        10:06:06   Log-Likelihood:                -155.65\n",
       "converged:                       True   LL-Null:                       -189.92\n",
       "Covariance Type:            nonrobust   LLR p-value:                   0.03396\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Home          -0.1375      0.207     -0.663      0.507      -0.544       0.269\n",
       "FIP_SP        -0.4355      0.298     -1.462      0.144      -1.019       0.148\n",
       "FIP_RP        -0.6125      0.261     -2.345      0.019      -1.125      -0.101\n",
       "WAR_SP         0.1019      0.279      0.365      0.715      -0.446       0.650\n",
       "WAR_RP        -0.1953      0.209     -0.936      0.349      -0.604       0.213\n",
       "OPS+_1         0.2028      1.295      0.157      0.876      -2.334       2.740\n",
       "OPS+_2         1.1703      1.011      1.158      0.247      -0.811       3.151\n",
       "OPS+_3         3.3496      1.900      1.763      0.078      -0.374       7.073\n",
       "OPS+_4        -0.9504      1.381     -0.688      0.491      -3.657       1.756\n",
       "OPS+_5         0.2036      1.803      0.113      0.910      -3.330       3.737\n",
       "OPS+_6         0.9630      1.357      0.710      0.478      -1.696       3.622\n",
       "OPS+_7        -0.6260      0.748     -0.837      0.402      -2.091       0.839\n",
       "OPS+_8        -0.2688      0.664     -0.405      0.685      -1.569       1.032\n",
       "OPS+_9        -0.9037      0.888     -1.018      0.309      -2.644       0.836\n",
       "BB/K_1        -0.1484      0.333     -0.445      0.656      -0.802       0.505\n",
       "BB/K_2         0.2010      0.259      0.777      0.437      -0.306       0.708\n",
       "BB/K_3        -0.0593      0.252     -0.235      0.814      -0.554       0.435\n",
       "BB/K_4        -0.5134      0.284     -1.810      0.070      -1.069       0.042\n",
       "BB/K_5         0.0484      0.229      0.211      0.833      -0.401       0.498\n",
       "BB/K_6         0.0999      0.179      0.557      0.577      -0.251       0.451\n",
       "BB/K_7        -0.0046      0.185     -0.025      0.980      -0.368       0.358\n",
       "BB/K_8        -0.0558      0.253     -0.221      0.825      -0.552       0.440\n",
       "BB/K_9         0.0833      0.221      0.377      0.706      -0.350       0.517\n",
       "BABIP_1       -0.0005      0.374     -0.001      0.999      -0.734       0.733\n",
       "BABIP_2        0.1457      0.261      0.558      0.577      -0.366       0.657\n",
       "BABIP_3       -0.4921      0.357     -1.380      0.167      -1.191       0.207\n",
       "BABIP_4       -0.1104      0.524     -0.211      0.833      -1.137       0.916\n",
       "BABIP_5       -0.3681      0.271     -1.360      0.174      -0.898       0.162\n",
       "BABIP_6        0.3748      0.344      1.090      0.276      -0.299       1.049\n",
       "BABIP_7        0.1804      0.287      0.629      0.529      -0.382       0.743\n",
       "BABIP_8        0.1978      0.333      0.593      0.553      -0.456       0.851\n",
       "BABIP_9        0.2449      0.324      0.756      0.449      -0.390       0.880\n",
       "wOBA_1        28.5642     43.954      0.650      0.516     -57.584     114.712\n",
       "wOBA_2       -24.3056     28.623     -0.849      0.396     -80.406      31.795\n",
       "wOBA_3         8.5220     34.212      0.249      0.803     -58.532      75.576\n",
       "wOBA_4       -46.2625     45.454     -1.018      0.309    -135.352      42.827\n",
       "wOBA_5        45.2661     31.977      1.416      0.157     -17.408     107.940\n",
       "wOBA_6        -5.5840     39.549     -0.141      0.888     -83.099      71.931\n",
       "wOBA_7        31.8981     32.745      0.974      0.330     -32.280      96.076\n",
       "wOBA_8       -53.9648     45.479     -1.187      0.235    -143.101      35.172\n",
       "wOBA_9        22.1206     43.547      0.508      0.611     -63.229     107.471\n",
       "wRC+_1       -28.3870     44.209     -0.642      0.521    -115.035      58.261\n",
       "wRC+_2        23.3727     28.436      0.822      0.411     -32.360      79.106\n",
       "wRC+_3       -11.1826     33.702     -0.332      0.740     -77.236      54.871\n",
       "wRC+_4        47.5405     45.667      1.041      0.298     -41.965     137.046\n",
       "wRC+_5       -45.0429     31.816     -1.416      0.157    -107.402      17.316\n",
       "wRC+_6         4.1075     39.682      0.104      0.918     -73.668      81.883\n",
       "wRC+_7       -31.2643     32.728     -0.955      0.339     -95.410      32.881\n",
       "wRC+_8        53.9820     45.333      1.191      0.234     -34.870     142.834\n",
       "wRC+_9       -21.3938     43.495     -0.492      0.623    -106.642      63.854\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "fiscal-munich",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.40      0.44         5\n",
      "           1       0.57      0.67      0.62         6\n",
      "\n",
      "    accuracy                           0.55        11\n",
      "   macro avg       0.54      0.53      0.53        11\n",
      "weighted avg       0.54      0.55      0.54        11\n",
      "\n",
      "[[2 3]\n",
      " [2 4]]\n"
     ]
    }
   ],
   "source": [
    "yhat = log_reg.predict(X_test.astype(float))\n",
    "prediction = list(map(round, yhat))\n",
    "print(classification_report(y_test.astype(float).astype(int),prediction))\n",
    "print(confusion_matrix(y_test.astype(float).astype(int),prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "fossil-secondary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.657066\n",
      "         Iterations 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>Win</td>       <th>  No. Observations:  </th>  <td>   274</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   271</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     2</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Fri, 20 Aug 2021</td> <th>  Pseudo R-squ.:     </th>  <td>0.05205</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>10:06:59</td>     <th>  Log-Likelihood:    </th> <td> -180.04</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -189.92</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>5.087e-05</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FIP_RP</th> <td>   -0.6276</td> <td>    0.172</td> <td>   -3.655</td> <td> 0.000</td> <td>   -0.964</td> <td>   -0.291</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>OPS+_3</th> <td>    0.0412</td> <td>    0.127</td> <td>    0.325</td> <td> 0.745</td> <td>   -0.207</td> <td>    0.289</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BB/K_4</th> <td>   -0.1318</td> <td>    0.127</td> <td>   -1.039</td> <td> 0.299</td> <td>   -0.381</td> <td>    0.117</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                    Win   No. Observations:                  274\n",
       "Model:                          Logit   Df Residuals:                      271\n",
       "Method:                           MLE   Df Model:                            2\n",
       "Date:                Fri, 20 Aug 2021   Pseudo R-squ.:                 0.05205\n",
       "Time:                        10:06:59   Log-Likelihood:                -180.04\n",
       "converged:                       True   LL-Null:                       -189.92\n",
       "Covariance Type:            nonrobust   LLR p-value:                 5.087e-05\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "FIP_RP        -0.6276      0.172     -3.655      0.000      -0.964      -0.291\n",
       "OPS+_3         0.0412      0.127      0.325      0.745      -0.207       0.289\n",
       "BB/K_4        -0.1318      0.127     -1.039      0.299      -0.381       0.117\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_prune = sm.Logit(y_train.astype(float), X_train[['FIP_RP','OPS+_3','BB/K_4']].astype(float)).fit()\n",
    "log_reg_prune.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "liquid-alabama",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.60      0.60         5\n",
      "           1       0.67      0.67      0.67         6\n",
      "\n",
      "    accuracy                           0.64        11\n",
      "   macro avg       0.63      0.63      0.63        11\n",
      "weighted avg       0.64      0.64      0.64        11\n",
      "\n",
      "[[3 2]\n",
      " [2 4]]\n"
     ]
    }
   ],
   "source": [
    "yhat = log_reg_prune.predict(X_test[['FIP_RP','OPS+_3','BB/K_4']].astype(float))\n",
    "prediction = list(map(round, yhat))\n",
    "print(classification_report(y_test.astype(float).astype(int),prediction))\n",
    "print(confusion_matrix(y_test.astype(float).astype(int),prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unsigned-taxation",
   "metadata": {},
   "source": [
    "#### 結論\n",
    "\n",
    "從中華職棒、CPBLSTAT爬下球賽勝負和球員的進階數據發現  \n",
    "將所有變數丟進羅吉斯迴歸，對於勝負最有顯著影響的是  \n",
    "後援投手的 FIP  \n",
    "第三棒打者的 OPS+  \n",
    "第四棒打者的 BB/K \n",
    "  \n",
    "FIP 是「投手獨立防禦率」  \n",
    "此數據的計算扣除了野手的守備因素 (例如站位)  \n",
    "只參考投手三振、保送、觸身球、被全壘打率的表現，試圖用成因大多「僅能由投手控制」的幾個數據，更正確評價投手的實質投球內容  \n",
    "FIP愈低的話，顯示投手的三振多、保送少、且不容易被打全壘打  \n",
    "  \n",
    "OPS+ 「標準化攻擊指數」  \n",
    "先計算攻擊指數 OPS = 「上壘率」和「長打率」，能代表一名打者綜合的進攻破壞力（上壘能力與長打火力）  \n",
    "再把攻擊指數「去脈絡化」，都放在同一個比較基準點上，排除原本數據當中的許多雜音，例如球場因素（球員數據會受到所在主場的影響）  \n",
    "得到 OPS+  \n",
    "\n",
    "BB/K 為四壞三振比，評判打擊者選球功力，數值越大代表越會選球 \n",
    "\n",
    "\n",
    "接著我們把 FIP_RP, OPS+_3, BB/K_4 拉出來獨立建模  \n",
    "發現 OPS+_3, BB/K_4 不顯著了  \n",
    "在中職，打擊居然不是勝負的主要因素 ???  \n",
    "\n",
    "現在只剩下 FIP   \n",
    "觀察 FIP 的係數都是負的  \n",
    "也就是說  \n",
    "派出好的後援投手，只是降低球隊輸球的機率，不是增加贏球機率\n",
    "也就是說當球隊在領先時，後援投手不要砸鍋放火就好\n",
    "  \n",
    "此模型對於勝負的解釋能力只有 5%   \n",
    "中華職棒官網的數據與CPBLSTAT的數據對於預測勝負的幫助並不大  \n",
    "試著用 8/12之後的 Test Data 去預測勝負  \n",
    "準確率 64%  \n",
    "預測能力不高  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outdoor-variable",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
